{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43674fb1-bc46-4924-b740-ea8baa17c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43e5b0-419b-463b-a0e8-780924a940c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bcfe7-6a76-4fb2-a517-8b04c8df4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "image_data_dir = r\"C:\\Users\\siddh\\Downloads\\archive (2)\\Data\\images_original\"\n",
    "additional_data_file = r\"C:\\Users\\siddh\\Downloads\\archive (2)\\Data\\features_30_sec.csv\"\n",
    "num_features = 58  # Number of features in the additional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ed743-df18-4f06-a684-ebcf7fa14788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Get list of subdirectories (each representing a class)\n",
    "class_directories = [os.path.join(image_data_dir, d) for d in os.listdir(image_data_dir) if os.path.isdir(os.path.join(image_data_dir, d))]\n",
    "\n",
    "# Set the number of images to display per row\n",
    "images_per_row = 5\n",
    "\n",
    "# Create subplots with specified number of rows and columns\n",
    "num_rows = len(class_directories)\n",
    "num_cols = images_per_row\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3*num_rows))\n",
    "\n",
    "# Iterate over each class directory\n",
    "for i, class_dir in enumerate(class_directories):\n",
    "    # Get list of image files in the directory\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "    if image_files:\n",
    "        # Take the first 5 images from the directory (or less if there are fewer than 5 images)\n",
    "        for j in range(min(len(image_files), images_per_row)):\n",
    "            image_path = os.path.join(class_dir, image_files[j])\n",
    "            # Load and display the image\n",
    "            img = mpimg.imread(image_path)\n",
    "            ax = axes[i, j] if num_rows > 1 else axes[j]  # Handle single row case\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')  # Turn off axis numbers and ticks\n",
    "            ax.set_title(os.path.basename(class_dir))  # Set title as directory name\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c992c-e877-4974-b835-a592e65e80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the image dataset\n",
    "def load_image_dataset(image_data_dir):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "    for label in os.listdir(image_data_dir):\n",
    "        label_dir = os.path.join(image_data_dir, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for filename in os.listdir(label_dir):\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "                    image_path = os.path.join(label_dir, filename)\n",
    "                    img = mpimg.imread(image_path)\n",
    "                    #img = img / 255.0\n",
    "                    image_data.append(img)\n",
    "                    labels.append(label)\n",
    "    return image_data, labels\n",
    "\n",
    "# Function to load and preprocess the additional dataset\n",
    "def load_additional_dataset(additional_data_file):\n",
    "    additional_data_df = pd.read_csv(additional_data_file)\n",
    "    additional_data_df.drop(columns=[\"length\"], inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    additional_data_df[additional_data_df.columns[1:-1]] = scaler.fit_transform(additional_data_df[additional_data_df.columns[1:-1]])\n",
    "    return additional_data_df\n",
    "\n",
    "# Load image dataset\n",
    "image_data, labels = load_image_dataset(image_data_dir)\n",
    "\n",
    "# Load additional dataset\n",
    "additional_data_df = load_additional_dataset(additional_data_file)\n",
    "\n",
    "\n",
    "print(\"Number of samples in image_data:\", len(image_data))\n",
    "print(\"Number of samples in additional_data_df:\", len(additional_data_df))\n",
    "print(\"Number of samples in Labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be43d72-b664-45d9-8e29-6dd3c77b56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of X_train_img:\", image_data[0].dtype)\n",
    "print(\"Shape of X_train_img:\", image_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dbdd2-91ea-4512-9b2c-af1fce83ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847e34c-eb5c-439a-82d8-2f48828e3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a target label for each image, convert labels to one-hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Define the columns to exclude\n",
    "columns_to_exclude = ['filename', 'label']\n",
    "\n",
    "# Select only the columns you need for training and validation\n",
    "selected_columns = [col for col in additional_data_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Split the data\n",
    "X_train_img, X_val_img, X_train_features, X_val_features, y_train, y_val = train_test_split(\n",
    "    image_data,\n",
    "    additional_data_df[selected_columns].values,  # Selecting only the required columns\n",
    "    one_hot_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8607657-4ba0-4f00-a7f3-8c7228c1584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numpy arrays\n",
    "print(\"Size of X_train_features:\", X_train_features.shape)\n",
    "print(\"Size of X_val_features:\", X_val_features.shape)\n",
    "print(\"Size of y_train:\", y_train.shape)\n",
    "print(\"Size of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34963f3-8dc8-40af-94e1-6d7e0b39bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model for image processing\n",
    "img_height, img_width = 288, 432\n",
    "# Define input shape\n",
    "input_shape = (32, 288, 432, 4)\n",
    "num_features = (None, 57)\n",
    "\n",
    "# Define CNN model for image processing\n",
    "image_input = tf.keras.Input(shape=input_shape[1:])\n",
    "#image_input = tf.keras.Input(shape=(img_height, img_width, 4))\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(image_input)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "image_output = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "# Define the input layer for the features dataset\n",
    "features_input = tf.keras.Input(shape=num_features[1:])\n",
    "\n",
    "# Concatenate the outputs of the CNN model and the features input\n",
    "concatenated = layers.concatenate([image_output, features_input])\n",
    "\n",
    "# Define additional dense layers for further processing\n",
    "x = layers.Dense(128, activation='relu')(concatenated)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Define the final model\n",
    "model = tf.keras.Model(inputs=[image_input, features_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae00d23-aabb-4792-a09d-5849a37de422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image arrays to tensors\n",
    "X_train_img_tensor = tf.convert_to_tensor(X_train_img)\n",
    "X_val_img_tensor = tf.convert_to_tensor(X_val_img)\n",
    "\n",
    "print(\"Data Type of X_train_img:\", X_train_img_tensor.dtype)\n",
    "print(\"Shape of X_train_img:\", X_train_img_tensor.shape)\n",
    "\n",
    "print(\"Data Type of X_val_img:\", X_val_img_tensor.dtype)\n",
    "print(\"Shape of X_val_img:\", X_val_img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9ab4a-88fb-446c-8adc-9328a1731ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit([X_train_img_tensor, X_train_features], y_train,\n",
    "                    validation_data=([X_val_img_tensor, X_val_features], y_val), \n",
    "                    epochs=30, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9c08c-8964-4d44-8a38-e02ef64e1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained your model and obtained the 'history' object\n",
    "# model.fit([...])\n",
    "\n",
    "# Obtain predictions on validation data\n",
    "y_pred_proba = model.predict([X_val_img_tensor, X_val_features])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Convert multilabel-indicator to single array of integers\n",
    "y_val_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_val_labels, y_pred)\n",
    "precision = precision_score(y_val_labels, y_pred, average='weighted')\n",
    "recall = recall_score(y_val_labels, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val_labels, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3664a-f573-4ff6-9108-3aa2ca71dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape1 = (32, 288, 432, 4)\n",
    "\n",
    "# Define CNN model for image processing\n",
    "image_input1 = tf.keras.Input(shape=input_shape1[1:])\n",
    "#image_input = tf.keras.Input(shape=(img_height, img_width, 4))\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(image_input1)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, 2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output1 = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Define the final model\n",
    "model1 = tf.keras.Model(inputs=[image_input1], outputs=output1)\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247eab6-2e5b-49ac-ba00-3dec7f2110cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit([X_train_img_tensor], y_train,\n",
    "                    validation_data=([X_val_img_tensor], y_val), \n",
    "                    epochs=30, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510efd38-a226-4c79-8b50-b9cca86c3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions on validation data\n",
    "y_pred_proba1 = model1.predict([X_val_img_tensor])\n",
    "y_pred1 = np.argmax(y_pred_proba1, axis=1)\n",
    "\n",
    "# Convert multilabel-indicator to single array of integers\n",
    "y_val_labels1 = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy1 = accuracy_score(y_val_labels1, y_pred1)\n",
    "precision1 = precision_score(y_val_labels1, y_pred1, average='weighted')\n",
    "recall1 = recall_score(y_val_labels1, y_pred1, average='weighted')\n",
    "f11 = f1_score(y_val_labels1, y_pred1, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print(\"Precision:\", precision1)\n",
    "print(\"Recall:\", recall1)\n",
    "print(\"F1 Score:\", f11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d7409-06e6-467a-b3a7-a22eb01d97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "algorithms = ['Random Forest', 'XGB', 'LSTM', 'CNN']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "rf_values = [0.8571428571428571, 0.8572001243506782, 0.8576325875124603, 0.8559601851531531,\n",
    "             0.8878, 0.8874, 0.8881, 0.8870]\n",
    "xgb_values = [0.8932362754018806, 0.8934990005949899, 0.8937220039659785, 0.8930229775741804,\n",
    "              0.9029, 0.9028, 0.9033, 0.9028]\n",
    "lstm_values = [0.9224, 0.9221, 0.922, 0.9217,\n",
    "               0.9054, 0.9058, 0.9053, 0.9054]\n",
    "cnn_values = [0.42, 0.4572360206339335, 0.42, 0.43180579228963095,\n",
    "             0.66, 0.5614711701342135, 0.535, 0.5407217221732509]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 20))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(algorithms))\n",
    "    ax.bar(index - bar_width/2, [rf_values[i], xgb_values[i], lstm_values[i], cnn_values[i]], bar_width, label='Pre-Tuning')\n",
    "    ax.bar(index + bar_width/2, [rf_values[i+4], xgb_values[i+4], lstm_values[i+4], cnn_values[i+4]], bar_width, label='Post-Tuning')\n",
    "    ax.set_xlabel('Algorithms')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(algorithms)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9493afc-373e-4edf-a9d1-d09a5b071089",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = [0.1428, 0.2651, 0.3118, 0.3767, 0.3943, 0.4826, 0.5344, 0.5976, 0.5457, 0.6263, 0.6571, 0.6473, 0.6669, 0.7010, 0.7172, 0.7340, 0.7560, 0.7553, 0.8413, 0.8176]\n",
    "loss1 = [2.3602, 2.2222, 2.1178, 1.9549, 1.7423, 1.5332, 1.3737, 1.2798, 1.2806, 1.1256, 1.0824, 1.0399, 0.9748, 0.8987, 0.8448, 0.7857, 0.7057, 0.6566, 0.5268, 0.5183]\n",
    "val_accuracy1 = [0.1500, 0.2150, 0.3150, 0.3200, 0.4200, 0.5050, 0.5450, 0.4500, 0.5700, 0.5850, 0.5550, 0.6150, 0.6100, 0.6100, 0.6150, 0.6550, 0.6150, 0.6450, 0.5600, 0.6600]\n",
    "val_loss1 = [2.2664, 2.1856, 2.0665, 1.8547, 1.6667, 1.4419, 1.3817, 1.4087, 1.2387, 1.2014, 1.1974, 1.1191, 1.1375, 1.0967, 1.0597, 1.0910, 1.0304, 1.1597, 1.2177, 1.0096]\n",
    "\n",
    "accuracy2 = [0.0737, 0.1088, 0.1375, 0.1779, 0.2177, 0.2741, 0.2610, 0.3150, 0.3347, 0.3557, 0.3824, 0.4087, 0.4419, 0.4351, 0.4871, 0.5421, 0.5947, 0.6398, 0.6699, 0.7267]\n",
    "loss2 = [2.3849, 2.3015, 2.2860, 2.1764, 2.0949, 1.9899, 1.9861, 1.8675, 1.8718, 1.7999, 1.7546, 1.6350, 1.6067, 1.5835, 1.4689, 1.2682, 1.1605, 1.0291, 0.9281, 0.8064]\n",
    "val_accuracy2 = [0.0650, 0.0650, 0.1700, 0.2600, 0.2550, 0.2350, 0.2650, 0.3100, 0.2900, 0.2800, 0.3450, 0.3350, 0.3800, 0.3650, 0.3600, 0.3450, 0.3750, 0.4000, 0.4000, 0.4250]\n",
    "val_loss2 = [2.3030, 2.3038, 2.2261, 2.0776, 1.9864, 1.9765, 1.9178, 1.8655, 1.8811, 1.9306, 1.8719, 1.8275, 1.8799, 1.8763, 1.9635, 1.9437, 2.0844, 2.2846, 2.1514, 2.1100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac6915-55fb-4547-9cc2-eca43e888bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "epochs = list(range(1, 21))\n",
    "\n",
    "# First set of data\n",
    "accuracy1 = [0.1428, 0.2651, 0.3118, 0.3767, 0.3943, 0.4826, 0.5344, 0.5976, 0.5457, 0.6263, 0.6571, 0.6473, 0.6669, 0.7010, 0.7172, 0.7340, 0.7560, 0.7553, 0.8413, 0.8176]\n",
    "loss1 = [2.3602, 2.2222, 2.1178, 1.9549, 1.7423, 1.5332, 1.3737, 1.2798, 1.2806, 1.1256, 1.0824, 1.0399, 0.9748, 0.8987, 0.8448, 0.7857, 0.7057, 0.6566, 0.5268, 0.5183]\n",
    "val_accuracy1 = [0.1500, 0.2150, 0.3150, 0.3200, 0.4200, 0.5050, 0.5450, 0.4500, 0.5700, 0.5850, 0.5550, 0.6150, 0.6100, 0.6100, 0.6150, 0.6550, 0.6150, 0.6450, 0.5600, 0.6600]\n",
    "val_loss1 = [2.2664, 2.1856, 2.0665, 1.8547, 1.6667, 1.4419, 1.3817, 1.4087, 1.2387, 1.2014, 1.1974, 1.1191, 1.1375, 1.0967, 1.0597, 1.0910, 1.0304, 1.1597, 1.2177, 1.0096]\n",
    "\n",
    "# Second set of data\n",
    "accuracy2 = [0.0737, 0.1088, 0.1375, 0.1779, 0.2177, 0.2741, 0.2610, 0.3150, 0.3347, 0.3557, 0.3824, 0.4087, 0.4419, 0.4351, 0.4871, 0.5421, 0.5947, 0.6398, 0.6699, 0.7267]\n",
    "loss2 = [2.3849, 2.3015, 2.2860, 2.1764, 2.0949, 1.9899, 1.9861, 1.8675, 1.8718, 1.7999, 1.7546, 1.6350, 1.6067, 1.5835, 1.4689, 1.2682, 1.1605, 1.0291, 0.9281, 0.8064]\n",
    "val_accuracy2 = [0.0650, 0.0650, 0.1700, 0.2600, 0.2550, 0.2350, 0.2650, 0.3100, 0.2900, 0.2800, 0.3450, 0.3350, 0.3800, 0.3650, 0.3600, 0.3450, 0.3750, 0.4000, 0.4000, 0.4250]\n",
    "val_loss2 = [2.3030, 2.3038, 2.2261, 2.0776, 1.9864, 1.9765, 1.9178, 1.8655, 1.8811, 1.9306, 1.8719, 1.8275, 1.8799, 1.8763, 1.9635, 1.9437, 2.0844, 2.2846, 2.1514, 2.1100]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, accuracy1, label='Accuracy 1', marker='o')\n",
    "plt.plot(epochs, accuracy2, label='Accuracy 2', marker='x')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, loss1, label='Loss 1', marker='o')\n",
    "plt.plot(epochs, loss2, label='Loss 2', marker='x')\n",
    "plt.title('Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, val_accuracy1, label='Validation Accuracy 1', marker='o')\n",
    "plt.plot(epochs, val_accuracy2, label='Validation Accuracy 2', marker='x')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, val_loss1, label='Validation Loss 1', marker='o')\n",
    "plt.plot(epochs, val_loss2, label='Validation Loss 2', marker='x')\n",
    "plt.title('Validation Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186c4a7-32fe-4e8c-8bd0-88e31802dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, val_accuracy1, label='Validation Accuracy 1', marker='o')\n",
    "plt.plot(epochs, val_accuracy2, label='Validation Accuracy 2', marker='x')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, val_loss1, label='Validation Loss 1', marker='o')\n",
    "plt.plot(epochs, val_loss2, label='Validation Loss 2', marker='x')\n",
    "plt.title('Validation Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9b3c0-d3be-4d2e-b798-32893d47356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, accuracy1, label='Images + Features Data')\n",
    "plt.plot(epochs, accuracy2, label='Images')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, loss1, label='Images + Features Data')\n",
    "plt.plot(epochs, loss2, label='Images')\n",
    "plt.title('Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, val_accuracy1, label='Images + Features Data')\n",
    "plt.plot(epochs, val_accuracy2, label='Images')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, val_loss1, label='Images + Features Data')\n",
    "plt.plot(epochs, val_loss2, label='Images')\n",
    "plt.title('Validation Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24d47c-18ff-4205-84c6-c1bb3cc0e042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
